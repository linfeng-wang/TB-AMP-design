{
  "os":  "Linux-4.15.0-197-generic-x86_64-with-glibc2.27",
  "python":  "CPython 3.10.16",
  "startedAt":  "2025-03-04T16:31:24.024647Z",
  "args":  [
    "--model_name_or_path",
    "nferruz/ProtGPT2",
    "--train_file",
    "all_seq702-train.csv",
    "--validation_file",
    "all_seq702-test.csv",
    "--tokenizer_name",
    "nferruz/ProtGPT2",
    "--do_train",
    "--do_eval",
    "--output_dir",
    "output",
    "--learning_rate",
    "1e-06"
  ],
  "program":  "/mnt/storageG1/lwang/Projects/TB-AMP-design/ProtGPT2/run_clm.py",
  "codePath":  "ProtGPT2/run_clm.py",
  "git":  {
    "remote":  "https://github.com/linfeng-wang/TB-AMP-design.git",
    "commit":  "5a54a59958abe3d311abaa020a79627b9f29d8c5"
  },
  "email":  "wanglinfeng1115@gmail.com",
  "root":  "/mnt/storageG1/lwang/Projects/TB-AMP-design/ProtGPT2",
  "host":  "plum-g1",
  "executable":  "/mnt/storageG1/lwang/miniconda3/envs/new-ml/bin/python",
  "codePathLocal":  "run_clm.py",
  "cpu_count":  48,
  "cpu_count_logical":  96,
  "gpu":  "Tesla V100-PCIE-32GB",
  "gpu_count":  1,
  "disk":  {
    "/":  {
      "total":  "116717178880",
      "used":  "86899634176"
    }
  },
  "memory":  {
    "total":  "1077713481728"
  },
  "cpu":  {
    "count":  48,
    "countLogical":  96
  },
  "gpu_nvidia":  [
    {
      "name":  "Tesla V100-PCIE-32GB",
      "memoryTotal":  "34089730048",
      "architecture":  "Volta"
    }
  ],
  "cudaVersion":  "11.1"
}