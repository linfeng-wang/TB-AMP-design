{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from icecream import ic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manual FASTA parsing (without Biopython)\n",
    "# fasta_path = \"../data//naturalAMPs_APD2024a-ADAM.fasta.txt\"\n",
    "\n",
    "# # Read lines from the FASTA file\n",
    "# with open(fasta_path, \"r\") as f:\n",
    "#     lines = f.read().strip().splitlines()\n",
    "\n",
    "# # Parse into (ID, Sequence) pairs\n",
    "# records = []\n",
    "# current_id = None\n",
    "# current_seq = []\n",
    "# for line in lines:\n",
    "#     if line.startswith(\">\"):\n",
    "#         if current_id is not None:\n",
    "#             records.append([current_id, ''.join(current_seq)])\n",
    "#         current_id = line[1:].strip()\n",
    "#         current_seq = []\n",
    "#     else:\n",
    "#         current_seq.append(line.strip())\n",
    "\n",
    "# # Add the last record\n",
    "# if current_id is not None:\n",
    "#     records.append([current_id, ''.join(current_seq)])\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df_fasta_manual = pd.DataFrame(records, columns=[\"Peptide ID\", \"Sequence\"])\n",
    "# df_fasta_manual.to_csv(\"../data/naturalAMPs_APD2024a-ADAM.csv\", index=False)\n",
    "\n",
    "\n",
    "# Manual FASTA parsing (without Biopython)\n",
    "# fasta_path = \"../data/uniprotkb_length_10_TO_80_NOT_antimicro_2025_04_14.fasta\"\n",
    "\n",
    "# # Read lines from the FASTA file\n",
    "# with open(fasta_path, \"r\") as f:\n",
    "#     lines = f.read().strip().splitlines()\n",
    "\n",
    "# # Parse into (ID, Sequence) pairs\n",
    "# records = []\n",
    "# current_id = None\n",
    "# current_seq = []\n",
    "# for line in lines:\n",
    "#     if line.startswith(\">\"):\n",
    "#         if current_id is not None:\n",
    "#             records.append([current_id, ''.join(current_seq)])\n",
    "#         current_id = line[1:].strip()\n",
    "#         current_seq = []\n",
    "#     else:\n",
    "#         current_seq.append(line.strip())\n",
    "\n",
    "# # Add the last record\n",
    "# if current_id is not None:\n",
    "#     records.append([current_id, ''.join(current_seq)])\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df_fasta_manual = pd.DataFrame(records, columns=[\"Peptide ID\", \"Sequence\"])\n",
    "# df_fasta_manual.to_csv(\"../data/uniprotkb_length_10_TO_80_NOT_antimicro_2025_04_14.fasta.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "# fasta_path = \"../data/uniprotkb_length_5_TO_30_NOT_antimicrob_2025_04_14.fasta (1)\"\n",
    "\n",
    "# # Read lines from the FASTA file\n",
    "# with open(fasta_path, \"r\") as f:\n",
    "#     lines = f.read().strip().splitlines()\n",
    "\n",
    "# # Parse into (ID, Sequence) pairs\n",
    "# records = []\n",
    "# current_id = None\n",
    "# current_seq = []\n",
    "# for line in lines:\n",
    "#     if line.startswith(\">\"):\n",
    "#         if current_id is not None:\n",
    "#             records.append([current_id, ''.join(current_seq)])\n",
    "#         current_id = line[1:].strip()\n",
    "#         current_seq = []\n",
    "#     else:\n",
    "#         current_seq.append(line.strip())\n",
    "\n",
    "# # Add the last record\n",
    "# if current_id is not None:\n",
    "#     records.append([current_id, ''.join(current_seq)])\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df_fasta_manual = pd.DataFrame(records, columns=[\"Peptide ID\", \"Sequence\"])\n",
    "# df_fasta_manual.to_csv(\"../data/uniprotkb_length_10_TO_80_NOT_antimicro_2025_04_14.fasta1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_df = pd.read_csv(\"../data/naturalAMPs_APD2024a-ADAM.csv\")\n",
    "uniprot_df = pd.read_csv(\"../data/uniprotkb_length_10_TO_80_NOT_antimicro_2025_04_14.fasta.csv\")\n",
    "uniprot_df1 = pd.read_csv(\"../data/uniprotkb_length_10_TO_80_NOT_antimicro_2025_04_14.fasta1.csv\")\n",
    "uniprot_df = pd.concat([uniprot_df, uniprot_df1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183 2\n",
      "Range of sequence lengths: 181\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sequence length: 34.4038112522686\n",
      "Median sequence length: 29.0\n",
      "Standard deviation of sequence lengths: 23.719451486351453\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate sequence lengths\n",
    "sequence_lengths = adam_df['Sequence'].apply(len)\n",
    "\n",
    "# Calculate the range of sequence lengths\n",
    "length_range = sequence_lengths.max() - sequence_lengths.min()\n",
    "print(sequence_lengths.max(),sequence_lengths.min())\n",
    "print(f\"Range of sequence lengths: {length_range}\")\n",
    "\n",
    "# Draw a box plot\n",
    "plt.boxplot(sequence_lengths)\n",
    "plt.title(\"Box Plot of Sequence Lengths\")\n",
    "plt.ylabel(\"Sequence Length\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate and display distribution statistics\n",
    "mean_length = sequence_lengths.mean()\n",
    "median_length = sequence_lengths.median()\n",
    "std_dev_length = sequence_lengths.std()\n",
    "\n",
    "print(f\"Mean sequence length: {mean_length}\")\n",
    "print(f\"Median sequence length: {median_length}\")\n",
    "print(f\"Standard deviation of sequence lengths: {std_dev_length}\")\n",
    "\n",
    "# adam_df = adam_df.drop(columns=['Sequence Length'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17692/3724575810.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_uniprot_df = uniprot_df.groupby('Sequence Length', group_keys=False).apply(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Peptide ID  \\\n",
      "81192  sp|P12997|BIOB_CITFR Biotin synthase (Fragment...   \n",
      "81715  sp|P85089|GTF2_LEUME Dextransucrase 2 (Fragmen...   \n",
      "81193  sp|P13071|BIOA_CITFR Adenosylmethionine-8-amin...   \n",
      "81176  sp|P0DKJ0|P160B_ARATH Peptide encoded by miPEP...   \n",
      "81362  sp|P41853|FARP_ARTTR FMRFamide-like neuropepti...   \n",
      "...                                                  ...   \n",
      "52463  tr|F5P1Z5|F5P1Z5_SHIFL ATP synthase subunit c ...   \n",
      "55078  sp|O28338|PURS_ARCFU Phosphoribosylformylglyci...   \n",
      "26968  tr|A0A4D5YML7|A0A4D5YML7_9ROSI ATP synthase su...   \n",
      "39606  tr|A0A7L3GVD8|A0A7L3GVD8_9PASS Serine palmitoy...   \n",
      "30647  tr|A0A5C1DC31|A0A5C1DC31_9ANNE Cytochrome c ox...   \n",
      "\n",
      "                                                Sequence  \n",
      "81192                                              MAHSS  \n",
      "81715                                              DSTNY  \n",
      "81193                                              MTTDD  \n",
      "81176                                              MFSPQ  \n",
      "81362                                              RYIRF  \n",
      "...                                                  ...  \n",
      "52463  MENLNMDLLYMAAAVMMGLAAIGAAIGIGILGGKFLEGAARQPDLI...  \n",
      "55078  MIADVYIELKEGVADPEGEATLKALRLLGFKRVKKVSTVKVFRIDI...  \n",
      "26968  NPLISAASVIAAGLAVGLASIGPGIGQGTAAGQAVEGIARQPEAEG...  \n",
      "39606  MDVRSTLSYLYWLFCQFELITCSYLMEPWEKVLFYSFNLAMLGLLL...  \n",
      "30647  GFGNWLVPLMLGAPDMAFPRINNLGFWLIPPAVILLVMSAFIEKGA...  \n",
      "\n",
      "[3739 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate sequence lengths for uniprot_df\n",
    "uniprot_df['Sequence Length'] = uniprot_df['Sequence'].apply(len)\n",
    "\n",
    "# Calculate sequence lengths for adam_df\n",
    "adam_df['Sequence Length'] = adam_df['Sequence'].apply(len)\n",
    "\n",
    "# Perform stratified sampling to select more samples\n",
    "sampled_uniprot_df = uniprot_df.groupby('Sequence Length', group_keys=False).apply(\n",
    "    lambda x: x.sample(\n",
    "        n=min(len(x), int(1.5 * adam_df['Sequence Length'].value_counts().get(x.name, 0))),  # Increase sample size\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop the 'Sequence Length' column after sampling\n",
    "sampled_uniprot_df = sampled_uniprot_df.drop(columns=['Sequence Length'])\n",
    "adam_df = adam_df.drop(columns=['Sequence Length'])\n",
    "\n",
    "# Draw a box plot to visualize the distribution\n",
    "plt.boxplot(sampled_uniprot_df['Sequence'].apply(len))\n",
    "plt.title(\"Box Plot of Sequence Lengths (Sampled Negatives)\")\n",
    "plt.ylabel(\"Sequence Length\")\n",
    "plt.show()\n",
    "\n",
    "print(sampled_uniprot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sequences'] = df['Sequences'].apply(lambda x: x.ljust(max_length, 'X'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "{'M', 'F', 'Z', 'G', 'K', 'P', 'D', 'Q', 'S', 'H', 'I', 'L', 'W', 'X', 'N', 'V', 'A', 'E', 'B', 'C', 'T', 'R', 'Y'}\n",
      "23\n",
      "{'B', 'Z'}\n",
      "Number of 'B' values: 2\n",
      "Number of sequences after filtering: 7042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "adam_df['label'] = 1\n",
    "sampled_uniprot_df['label'] = 0\n",
    "adam_df.columns = [\"Peptide ID\", \"Sequences\", 'label']\n",
    "sampled_uniprot_df.columns = [\"Peptide ID\", \"Sequences\" , 'label']\n",
    "df = pd.concat([adam_df, sampled_uniprot_df], ignore_index=True)\n",
    "\n",
    "max_length = df['Sequences'].str.len().max()\n",
    "print(max_length)\n",
    "# df['Sequences'] = df['Sequences'].apply(lambda x: x.ljust(max_length, 'X'))\n",
    "\n",
    "unique_letters = set(''.join(df[\"Sequences\"]))\n",
    "print(unique_letters)\n",
    "print(len(unique_letters))\n",
    "amino_acids = set(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
    "non_standard_amino_acids = unique_letters - amino_acids\n",
    "print(non_standard_amino_acids)\n",
    "b_count = df[\"Sequences\"].str.count('B').sum()\n",
    "print(f\"Number of 'B' values: {b_count}\")\n",
    "\n",
    "# Filter out sequences containing non-standard amino acids\n",
    "df = df[~df['Sequences'].str.contains('|'.join(non_standard_amino_acids))]\n",
    "print(f\"Number of sequences after filtering: {len(df)}\")\n",
    "\n",
    "X = df[\"Sequences\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Split into train (70%), validation (15%), test (15%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 2: Split train+val into train and val (stratified)\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test, y_test, test_size=0.5, random_state=42, stratify=y_test\n",
    ")  # 0.1765 to maintain 15% of original dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define One-Hot Encoding Function for DNA Sequences in PyTorch\n",
    "def one_hot_torch(seq: str, dtype=torch.float32):\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    seq_bytes = torch.ByteTensor(list(bytes(seq, \"utf-8\")))\n",
    "    aa_bytes = torch.ByteTensor(list(bytes(amino_acids, \"utf-8\")))\n",
    "    arr = torch.zeros(len(amino_acids), len(seq_bytes), dtype=dtype)\n",
    "    for i, aa in enumerate(aa_bytes):\n",
    "        arr[i, seq_bytes == aa] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, one_hot_dtype=torch.float32):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.one_hot_dtype = one_hot_dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        length = len(seq.replace(\"X\", \"\"))  # unpadded length\n",
    "        return one_hot_torch(seq, dtype=self.one_hot_dtype), torch.tensor(label, dtype=torch.float32), length\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "def collate_and_pack(batch):\n",
    "    # batch = list of (tensor_seq, label, length)\n",
    "    sequences, labels, lengths = zip(*batch)\n",
    "\n",
    "    # lengths as tensor\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    # Sort by descending length (required by pack_padded_sequence)\n",
    "    sorted_indices = torch.argsort(lengths, descending=True)\n",
    "    sequences = [sequences[i] for i in sorted_indices]\n",
    "    labels = torch.tensor([labels[i] for i in sorted_indices])\n",
    "    lengths = lengths[sorted_indices]\n",
    "\n",
    "    # Stack to shape: (batch_size, 20, seq_len) and transpose for LSTM input\n",
    "    # LSTM expects input of shape (seq_len, batch_size, features)\n",
    "    sequences = [seq.T for seq in sequences]  # Transpose each [20, L] to [L, 20]\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=False)  # shape: [max_len, batch, features]\n",
    "\n",
    "    # Pack the sequence\n",
    "    packed_input = pack_padded_sequence(padded_seqs, lengths.cpu(), batch_first=False)\n",
    "\n",
    "    return packed_input, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "Train: 4929\n",
      "Validation: 1057\n",
      "Test: 1056\n"
     ]
    }
   ],
   "source": [
    "# Define DataLoaders\n",
    "\n",
    "train_dataset = SequenceDataset(X_train, y_train)\n",
    "val_dataset = SequenceDataset(X_val, y_val)\n",
    "test_dataset = SequenceDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_and_pack)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_and_pack)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_and_pack)\n",
    "\n",
    "    \n",
    "# Display dataset sizes\n",
    "dataset_sizes = {\n",
    "    \"Train\": len(train_dataset),\n",
    "    \"Validation\": len(val_dataset),\n",
    "    \"Test\": len(test_dataset)\n",
    "}\n",
    "print(\"Dataset sizes:\")\n",
    "for name, size in dataset_sizes.items():\n",
    "    print(f\"{name}: {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=64, num_layers=1, dropout=0.3):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=False,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, packed_input):\n",
    "        # packed_input: PackedSequence\n",
    "        packed_output, (hn, cn) = self.lstm(packed_input)\n",
    "\n",
    "        # hn: [num_layers, batch_size, hidden_dim]\n",
    "        # We'll use the **last layer's** hidden state as feature\n",
    "        last_hidden = hn[-1]  # shape: [batch_size, hidden_dim]\n",
    "\n",
    "        # Fully connected + sigmoid\n",
    "        out = self.fc(last_hidden)       # shape: [batch_size, 1]\n",
    "        out = self.sigmoid(out).squeeze(1)  # shape: [batch_size]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[361 200]\n",
      " [ 30 466]]\n",
      "Sensitivity (Recall for Positive Class): 0.9395\n",
      "Specificity (Recall for Negative Class): 0.6435\n",
      "Epoch [1/10] - Train Loss: 0.6468, Val Loss: 0.5674, Val Acc: 0.7824, Val AUC: 0.8395\n",
      "\n",
      "Confusion Matrix:\n",
      "[[470  91]\n",
      " [ 65 431]]\n",
      "Sensitivity (Recall for Positive Class): 0.8690\n",
      "Specificity (Recall for Negative Class): 0.8378\n",
      "Epoch [2/10] - Train Loss: 0.4575, Val Loss: 0.3718, Val Acc: 0.8524, Val AUC: 0.9194\n",
      "\n",
      "Confusion Matrix:\n",
      "[[414 147]\n",
      " [ 34 462]]\n",
      "Sensitivity (Recall for Positive Class): 0.9315\n",
      "Specificity (Recall for Negative Class): 0.7380\n",
      "Epoch [3/10] - Train Loss: 0.3985, Val Loss: 0.4056, Val Acc: 0.8288, Val AUC: 0.9094\n",
      "\n",
      "Confusion Matrix:\n",
      "[[480  81]\n",
      " [ 60 436]]\n",
      "Sensitivity (Recall for Positive Class): 0.8790\n",
      "Specificity (Recall for Negative Class): 0.8556\n",
      "Epoch [4/10] - Train Loss: 0.4537, Val Loss: 0.3877, Val Acc: 0.8666, Val AUC: 0.9226\n",
      "\n",
      "Confusion Matrix:\n",
      "[[492  69]\n",
      " [ 63 433]]\n",
      "Sensitivity (Recall for Positive Class): 0.8730\n",
      "Specificity (Recall for Negative Class): 0.8770\n",
      "Epoch [5/10] - Train Loss: 0.3758, Val Loss: 0.3299, Val Acc: 0.8751, Val AUC: 0.9383\n",
      "\n",
      "Confusion Matrix:\n",
      "[[479  82]\n",
      " [ 54 442]]\n",
      "Sensitivity (Recall for Positive Class): 0.8911\n",
      "Specificity (Recall for Negative Class): 0.8538\n",
      "Epoch [6/10] - Train Loss: 0.3553, Val Loss: 0.3388, Val Acc: 0.8713, Val AUC: 0.9322\n",
      "\n",
      "Confusion Matrix:\n",
      "[[426 135]\n",
      " [ 35 461]]\n",
      "Sensitivity (Recall for Positive Class): 0.9294\n",
      "Specificity (Recall for Negative Class): 0.7594\n",
      "Epoch [7/10] - Train Loss: 0.4268, Val Loss: 0.3870, Val Acc: 0.8392, Val AUC: 0.9291\n",
      "\n",
      "Confusion Matrix:\n",
      "[[380 181]\n",
      " [ 84 412]]\n",
      "Sensitivity (Recall for Positive Class): 0.8306\n",
      "Specificity (Recall for Negative Class): 0.6774\n",
      "Epoch [8/10] - Train Loss: 0.4347, Val Loss: 0.5133, Val Acc: 0.7493, Val AUC: 0.8412\n",
      "\n",
      "Confusion Matrix:\n",
      "[[501  60]\n",
      " [ 62 434]]\n",
      "Sensitivity (Recall for Positive Class): 0.8750\n",
      "Specificity (Recall for Negative Class): 0.8930\n",
      "Epoch [9/10] - Train Loss: 0.3740, Val Loss: 0.3212, Val Acc: 0.8846, Val AUC: 0.9401\n",
      "\n",
      "Confusion Matrix:\n",
      "[[509  52]\n",
      " [ 68 428]]\n",
      "Sensitivity (Recall for Positive Class): 0.8629\n",
      "Specificity (Recall for Negative Class): 0.9073\n",
      "Epoch [10/10] - Train Loss: 0.3507, Val Loss: 0.3194, Val Acc: 0.8865, Val AUC: 0.9388\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=1e-3, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_auc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_auc': []}\n",
    "\n",
    "    # Set up TensorBoard writer\n",
    "    log_dir = f\"runs/AMP_LSTM_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for packed_input, labels in train_loader:\n",
    "            labels = labels.to(device)\n",
    "            packed_input = packed_input.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(packed_input)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "        # Run evaluation\n",
    "        val_loss, val_acc, val_auc = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        # Logging\n",
    "        writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n",
    "        writer.add_scalar('AUC/Validation', val_auc, epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Save to history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    writer.close()\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device='cuda' if torch.cuda.is_available() else 'cpu', verbose=False):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for packed_input, labels in data_loader:\n",
    "            labels = labels.to(device)\n",
    "            packed_input = packed_input.to(device)\n",
    "\n",
    "            outputs = model(packed_input)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    # Convert predicted probabilities to binary predictions\n",
    "    pred_labels = [1 if p > 0.5 else 0 for p in all_preds]\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(all_labels, pred_labels)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, pred_labels)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)  # handle corner cases\n",
    "\n",
    "    # Sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else float('nan')\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else float('nan')\n",
    "    if verbose:\n",
    "        # Print metrics\n",
    "        print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "        print(f\"Sensitivity (Recall for Positive Class): {sensitivity:.4f}\")\n",
    "        print(f\"Specificity (Recall for Negative Class): {specificity:.4f}\")\n",
    "\n",
    "    return avg_loss, acc, auc\n",
    "\n",
    "\n",
    "model = LSTMClassifier(hidden_dim=64)\n",
    "history = train_model(model, train_loader, val_loader, num_epochs=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding in regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[401 160]\n",
      " [ 89 407]]\n",
      "Sensitivity (Recall for Positive Class): 0.8206\n",
      "Specificity (Recall for Negative Class): 0.7148\n",
      "Epoch [1/10] - Train Loss: 0.6630, Val Loss: 0.5471, Val Acc: 0.7644, Val AUC: 0.8299\n",
      "\n",
      "Confusion Matrix:\n",
      "[[460 101]\n",
      " [101 395]]\n",
      "Sensitivity (Recall for Positive Class): 0.7964\n",
      "Specificity (Recall for Negative Class): 0.8200\n",
      "Epoch [2/10] - Train Loss: 0.5161, Val Loss: 0.4849, Val Acc: 0.8089, Val AUC: 0.8625\n",
      "\n",
      "Confusion Matrix:\n",
      "[[192 369]\n",
      " [ 29 467]]\n",
      "Sensitivity (Recall for Positive Class): 0.9415\n",
      "Specificity (Recall for Negative Class): 0.3422\n",
      "Epoch [3/10] - Train Loss: 0.6564, Val Loss: 0.6466, Val Acc: 0.6235, Val AUC: 0.8047\n",
      "\n",
      "Confusion Matrix:\n",
      "[[424 137]\n",
      " [119 377]]\n",
      "Sensitivity (Recall for Positive Class): 0.7601\n",
      "Specificity (Recall for Negative Class): 0.7558\n",
      "Epoch [4/10] - Train Loss: 0.5960, Val Loss: 0.5372, Val Acc: 0.7578, Val AUC: 0.8364\n",
      "\n",
      "Confusion Matrix:\n",
      "[[458 103]\n",
      " [ 77 419]]\n",
      "Sensitivity (Recall for Positive Class): 0.8448\n",
      "Specificity (Recall for Negative Class): 0.8164\n",
      "Epoch [5/10] - Train Loss: 0.4724, Val Loss: 0.3893, Val Acc: 0.8297, Val AUC: 0.9082\n",
      "\n",
      "Confusion Matrix:\n",
      "[[515  46]\n",
      " [121 375]]\n",
      "Sensitivity (Recall for Positive Class): 0.7560\n",
      "Specificity (Recall for Negative Class): 0.9180\n",
      "Epoch [6/10] - Train Loss: 0.3992, Val Loss: 0.3821, Val Acc: 0.8420, Val AUC: 0.9220\n",
      "\n",
      "Confusion Matrix:\n",
      "[[476  85]\n",
      " [ 67 429]]\n",
      "Sensitivity (Recall for Positive Class): 0.8649\n",
      "Specificity (Recall for Negative Class): 0.8485\n",
      "Epoch [7/10] - Train Loss: 0.3674, Val Loss: 0.3593, Val Acc: 0.8562, Val AUC: 0.9305\n",
      "\n",
      "Confusion Matrix:\n",
      "[[512  49]\n",
      " [ 91 405]]\n",
      "Sensitivity (Recall for Positive Class): 0.8165\n",
      "Specificity (Recall for Negative Class): 0.9127\n",
      "Epoch [8/10] - Train Loss: 0.3570, Val Loss: 0.3330, Val Acc: 0.8675, Val AUC: 0.9375\n",
      "\n",
      "Confusion Matrix:\n",
      "[[451 110]\n",
      " [ 55 441]]\n",
      "Sensitivity (Recall for Positive Class): 0.8891\n",
      "Specificity (Recall for Negative Class): 0.8039\n",
      "Epoch [9/10] - Train Loss: 0.4099, Val Loss: 0.3379, Val Acc: 0.8439, Val AUC: 0.9359\n",
      "\n",
      "Confusion Matrix:\n",
      "[[464  97]\n",
      " [ 43 453]]\n",
      "Sensitivity (Recall for Positive Class): 0.9133\n",
      "Specificity (Recall for Negative Class): 0.8271\n",
      "Epoch [10/10] - Train Loss: 0.3665, Val Loss: 0.3215, Val Acc: 0.8675, Val AUC: 0.9421\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=64, num_layers=1, dropout=0.3):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=False,\n",
    "            dropout=dropout if num_layers > 1 else 0  # LSTM dropout applies only between layers\n",
    "        )\n",
    "\n",
    "        # Dropout after LSTM (even if 1 layer)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Fully connected classifier\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, packed_input):\n",
    "        packed_output, (hn, cn) = self.lstm(packed_input)\n",
    "\n",
    "        # Get the last hidden state from the last layer\n",
    "        last_hidden = hn[-1]  # shape: [batch_size, hidden_dim]\n",
    "\n",
    "        # Apply dropout\n",
    "        dropped = self.dropout(last_hidden)\n",
    "\n",
    "        # Fully connected + sigmoid\n",
    "        out = self.fc(dropped)       # shape: [batch_size, 1]\n",
    "        out = self.sigmoid(out).squeeze(1)  # shape: [batch_size]\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=1e-3, weight_decay=1e-4,\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu', verbose=False):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)  # L2 regularization\n",
    "\n",
    "    best_val_auc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_auc': []}\n",
    "\n",
    "    # Set up TensorBoard writer\n",
    "    log_dir = f\"runs/AMP_LSTM_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for packed_input, labels in train_loader:\n",
    "            labels = labels.to(device)\n",
    "            packed_input = packed_input.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(packed_input)   \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "        # Run evaluation\n",
    "        val_loss, val_acc, val_auc = evaluate_model(model, val_loader, criterion, device, verbose=verbose)\n",
    "\n",
    "        # Logging\n",
    "        writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n",
    "        writer.add_scalar('AUC/Validation', val_auc, epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] - \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Val Acc: {val_acc:.4f}, \"\n",
    "              f\"Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # Save to history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    writer.close()\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, recall_score\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device='cuda' if torch.cuda.is_available() else 'cpu', verbose=False):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for packed_input, labels in data_loader:\n",
    "            labels = labels.to(device)\n",
    "            packed_input = packed_input.to(device)\n",
    "\n",
    "            outputs = model(packed_input)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    # Convert predicted probabilities to binary predictions\n",
    "    pred_labels = [1 if p > 0.5 else 0 for p in all_preds]\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(all_labels, pred_labels)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, pred_labels)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)  # handle corner cases\n",
    "\n",
    "    # Sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else float('nan')\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else float('nan')\n",
    "    if verbose:\n",
    "        # Print metrics\n",
    "        print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "        print(f\"Sensitivity (Recall for Positive Class): {sensitivity:.4f}\")\n",
    "        print(f\"Specificity (Recall for Negative Class): {specificity:.4f}\")\n",
    "\n",
    "    return avg_loss, acc, auc\n",
    "\n",
    "model = LSTMClassifier(input_dim=20, hidden_dim=64, dropout=0.5)\n",
    "history = train_model(model, train_loader, val_loader, num_epochs=10, lr=1e-3,\n",
    "                      weight_decay=1e-4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 18:16:10,389] A new study created in memory with name: no-name-28d289e6-6ebd-4e74-b291-35339928217b\n",
      "/tmp/ipykernel_17692/3329672761.py:120: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
      "/tmp/ipykernel_17692/3329672761.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2)\n",
      "[I 2025-04-14 18:22:59,737] Trial 0 finished with value: 0.9552785923753666 and parameters: {'hidden_dim': 84, 'num_layers': 3, 'dropout': 0.45512782378142325, 'lr': 0.0006169708164652774, 'weight_decay': 3.8005130735451964e-05}. Best is trial 0 with value: 0.9552785923753666.\n",
      "/tmp/ipykernel_17692/3329672761.py:120: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
      "/tmp/ipykernel_17692/3329672761.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2)\n",
      "[I 2025-04-14 18:29:00,006] Trial 1 finished with value: 0.951512276464838 and parameters: {'hidden_dim': 127, 'num_layers': 2, 'dropout': 0.1948614899739876, 'lr': 0.00102984246977777, 'weight_decay': 2.0514084371771065e-06}. Best is trial 0 with value: 0.9552785923753666.\n",
      "/tmp/ipykernel_17692/3329672761.py:120: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
      "/tmp/ipykernel_17692/3329672761.py:121: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "import datetime\n",
    "\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=20, hidden_dim=64, num_layers=1, dropout=0.3):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=False,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, packed_input):\n",
    "        packed_output, (hn, cn) = self.lstm(packed_input)\n",
    "        last_hidden = hn[-1]\n",
    "        dropped = self.dropout(last_hidden)\n",
    "        out = self.fc(dropped)\n",
    "        out = self.sigmoid(out).squeeze(1)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=1e-3, weight_decay=1e-4, device='cuda' if torch.cuda.is_available() else 'cpu', verbose=False):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    best_val_auc = 0.0\n",
    "\n",
    "    log_dir = f\"runs/AMP_LSTM_{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for packed_input, labels in train_loader:\n",
    "            labels = labels.to(device)\n",
    "            packed_input = packed_input.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(packed_input)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        val_loss, val_acc, val_auc = evaluate_model(model, val_loader, criterion, device, verbose=verbose)\n",
    "\n",
    "        writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n",
    "        writer.add_scalar('AUC/Validation', val_auc, epoch)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] - \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_acc:.4f}, \"\n",
    "                  f\"Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    writer.close()\n",
    "    return best_val_auc\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device='cuda' if torch.cuda.is_available() else 'cpu', verbose=False):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for packed_input, labels in data_loader:\n",
    "            labels = labels.to(device)\n",
    "            packed_input = packed_input.to(device)\n",
    "            outputs = model(packed_input)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    pred_labels = [1 if p > 0.5 else 0 for p in all_preds]\n",
    "    acc = accuracy_score(all_labels, pred_labels)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    cm = confusion_matrix(all_labels, pred_labels)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else float('nan')\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else float('nan')\n",
    "    if verbose:\n",
    "        print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "        print(f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "\n",
    "    return avg_loss, acc, auc\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 128)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2)\n",
    "\n",
    "    model = LSTMClassifier(input_dim=20, hidden_dim=hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "    val_auc = train_model(model, train_loader, val_loader, num_epochs=20, lr=lr,\n",
    "                          weight_decay=weight_decay, verbose=False)\n",
    "    return val_auc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### biLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
